https://colab.research.google.com/drive/1ERevvgRJAdEuWqMot9uCO3kQBTKw2VPN?authuser=2#scrollTo=lAlYYNP64IEZ

import math
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn import datasets
from sklearn.preprocessing import StandardScaler
from numpy import trapz
from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn import metrics
from sklearn.metrics import f1_score
from matplotlib.colors import ListedColormap

from sklearn.metrics import roc_curve, auc
from sklearn.metrics import roc_auc_score
from sklearn.metrics import accuracy_score, precision_score, recall_score

 # the first variant:
#w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 1
#n_iterations = 5000
#eta = 0.005
#threshold = 0.5

def Sigmoid(x):
    return 1/(1 + np.exp(-x))


#making some data
classes = datasets.make_classification(n_samples=10000, n_features=2, n_informative=2,
                                       n_redundant=0, n_classes=2, random_state=42)


np.random.seed(42)
shuffle_index = np.random.permutation(classes[0].shape[0])
X_shuffled, y_shuffled = classes[0][shuffle_index], classes[1][shuffle_index]
train_proportion = 0.7
train_test_cut = int(len(classes[0]) * train_proportion)

X_train, X_test, y_train, y_test = \
    X_shuffled[:train_test_cut], \
    X_shuffled[train_test_cut:], \
    y_shuffled[:train_test_cut], \
    y_shuffled[train_test_cut:]
X_train_tr = X_train.transpose()
y_train_tr = y_train.reshape(1, y_train.shape[0])
X_test_tr = X_test.transpose()
y_test_tr = y_test.reshape(1, y_test.shape[0])


ss_train = StandardScaler()
X_train = ss_train.fit_transform(X_train)

ss_test = StandardScaler()
X_test = ss_test.fit_transform(X_test)



def log_loss(w, X, y):
    m = X.shape[1]
    A = Sigmoid(np.dot(w.T, X))
    loss = -1.0 / m * np.sum(y * np.log(A) + (1 - y) * np.log(1 - A))
    loss = np.squeeze(loss)
    grad = 1.0 / m * np.dot(X, (A - y).T)
    
    return loss, grad

def optimize(w, X, y, n_iterations, eta):
    losses = []
    X = np.vstack((np.ones((1,X.shape[1])),X))
    for i in range(n_iterations):        
        loss, grad = log_loss(w, X, y)
        w = w - eta * grad
        losses.append(loss)
        
    return w, losses


def predict(w, X):
    
    m = X.shape[1]
    X = np.vstack((np.ones((1,X.shape[1])),X))

    y_predicted = np.zeros((1, m))
    w = w.reshape(X.shape[0], 1)
    A = Sigmoid(np.dot(w.T, X))
    
    for i in range(A.shape[1]):
        if (A[:,i] > 0.5): 
            y_predicted[:, i] = 1
        elif (A[:,i] <= 0.5):
            y_predicted[:, i] = 0
    return y_predicted


w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 1

n_iterations = 5000
eta = 0.005

w, losses = optimize(w0, X_train_tr, y_train_tr, n_iterations, eta)

y_predicted_test = predict(w, X_test_tr)
y_predicted_train = predict(w, X_train_tr)

train_accuracy = 100.0 - np.mean(np.abs(y_predicted_train - y_train_tr)*100.0)
test_accuracy = 100.0 - np.mean(np.abs(y_predicted_test-y_test_tr)*100.0)
print(f"Итоговый вектор весов w: {w}")
print(f"Точность на обучающей выборке: {train_accuracy:.3f}")
print(f"Точность на тестовой выборке: {test_accuracy:.3f}")

xl = np.array([[1,1],[-2,2],[-2,2]])*0.9
yt = np.dot(w.T, xl)

colors = ListedColormap(['red', 'blue','green'])
y_x = predict(w,classes[0].T)

plt.title('Log loss')
plt.xlabel('iterations')
plt.ylabel('loss')
plt.plot(range(len(losses)), losses)

plt.figure(figsize=(25, 16))
plt.subplot(1,2,1)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=classes[1], cmap=colors)
plt.grid()
plt.title('True y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.subplot(1,2,2)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=y_x.reshape(-1), cmap=colors)
plt.grid()
plt.title('Predict y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.show()

# print(y_test.shape)
# print(y_predicted_test.shape)
# lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)


#ROC-AUC


X_test_tr_sig = np.vstack((np.ones((1, X_test_tr.shape[1])),X_test_tr))
y_pred_log = Sigmoid(np.dot(w.T, X_test_tr_sig))
N = 50
plt.figure(figsize = (16, 5))
plt.subplot(1,2,1)
plt.plot(y_predicted_test[0,:N], 'r' , label = 'true')
plt.plot(y_test_tr[0,:N], '--', label = "class predict")
plt.legend()

plt.subplot(1,2,2)
plt.plot(y_predicted_test[0,:N], "r", label ="true")
plt.plot(y_pred_log[0,:N], "--", label = "log predict")
plt.legend()

plt.show()
y = pd.DataFrame(y_pred_log[0,:])
y[1] = y_test_tr[0,:]

TPR = []
FPR = []

for i in range (len(y.iloc[:,0])):
  tresholds = y.iloc[i,0]- 0.00000000001
  y_p = y.iloc[:,0]>tresholds
  c = [[np.sum((y.iloc[:,1]== 1) & (y_p == y.iloc[:,1])), np.sum((y.iloc[:,1] ==1) &(y_p != y.iloc[:,1]))],
       [np.sum((y.iloc[:,1] == 0) & (y_p != y.iloc[:,1])), np.sum((y.iloc[:,1] == 0)& (y_p == y.iloc[:,1]))]]
  TP = c[0][0]
  TN = c[1][1]
  FP = c[1][0]
  FN = c[0][1]

  TPR.append(TP/(TP+FN))
  FPR.append(FP/(FP+TN))

AUC_ROC = trapz(TPR, x = FPR, dx = 0.1)

plt.title('ROC curve')
plt.ylim(0, 1.05)
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.grid()
plt.legend('', title = f'AUC_ROC = {AUC_ROC:.3f}', loc="lower right")
plt.plot(FPR,TPR)
plt.show()



#импортированные встроенные метрики
# вопрос: насколько им можно верить?

lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)

#f1_score
from sklearn.metrics import f1_score
f1= f1_score(y_test,  lr_pred ,  average=None, zero_division="warn")
print(f'cреднее гармоническое точности и полноты f1_score:{f1} ')

#доля правильных ответов, точность, полнота алгоритма 
accuracy = accuracy_score(lr_pred, y_test)
precision = precision_score(lr_pred , y_test)
recall = recall_score(lr_pred , y_test)
print(f'доля правильных ответов алгоритма logR: {accuracy}, точность алгоритма logR:  {precision}, полнота алгоритма logR:  {recall} ')

#матрицa ошибок

cm = metrics.confusion_matrix(y_test, lr_pred)
plt.figure(figsize=(9,9))
sns.heatmap(cm,annot = True, fmt='.3f', linewidth=.5,square=True,cmap='Blues_r')
plt.xlabel('Actual label')
plt.ylabel('Predicted label')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy)
plt.title(all_sample_title,size = 15)
plt.show()


#A receiver operating characteristic curve (ROC curve)
#не уверена, наксолько  верно подправила эту ROC кривую.

y_pred_log_tr = y_pred_log.transpose()

fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_log_tr )
auc = metrics.roc_auc_score(y_test,  y_pred_log_tr )
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('A receiver operating characteristic curve')
plt.legend(loc="lower right")


#the second variant:
# w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 0.5
# n_iterations = 5000
# eta = 0.005
# threshold = 0.5

def Sigmoid(x):
    return 1/(1 + np.exp(-x))


#making some data
classes = datasets.make_classification(n_samples=10000, n_features=2, n_informative=2,
                                       n_redundant=0, n_classes=2, random_state=42)


np.random.seed(42)
shuffle_index = np.random.permutation(classes[0].shape[0])
X_shuffled, y_shuffled = classes[0][shuffle_index], classes[1][shuffle_index]
train_proportion = 0.7
train_test_cut = int(len(classes[0]) * train_proportion)

X_train, X_test, y_train, y_test = \
    X_shuffled[:train_test_cut], \
    X_shuffled[train_test_cut:], \
    y_shuffled[:train_test_cut], \
    y_shuffled[train_test_cut:]
X_train_tr = X_train.transpose()
y_train_tr = y_train.reshape(1, y_train.shape[0])
X_test_tr = X_test.transpose()
y_test_tr = y_test.reshape(1, y_test.shape[0])


ss_train = StandardScaler()
X_train = ss_train.fit_transform(X_train)

ss_test = StandardScaler()
X_test = ss_test.fit_transform(X_test)



def log_loss(w, X, y):
    m = X.shape[1]
    A = Sigmoid(np.dot(w.T, X))
    loss = -1.0 / m * np.sum(y * np.log(A) + (1 - y) * np.log(1 - A))
    loss = np.squeeze(loss)
    grad = 1.0 / m * np.dot(X, (A - y).T)
    
    return loss, grad

def optimize(w, X, y, n_iterations, eta):
    losses = []
    X = np.vstack((np.ones((1,X.shape[1])),X))
    for i in range(n_iterations):        
        loss, grad = log_loss(w, X, y)
        w = w - eta * grad
        losses.append(loss)
        
    return w, losses


def predict(w, X):
    
    m = X.shape[1]
    X = np.vstack((np.ones((1,X.shape[1])),X))

    y_predicted = np.zeros((1, m))
    w = w.reshape(X.shape[0], 1)
    A = Sigmoid(np.dot(w.T, X))
    
    for i in range(A.shape[1]):
        if (A[:,i] > 0.5): 
            y_predicted[:, i] = 1
        elif (A[:,i] <= 0.5):
            y_predicted[:, i] = 0
    return y_predicted


w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 0.5

n_iterations = 5000
eta = 0.005

w, losses = optimize(w0, X_train_tr, y_train_tr, n_iterations, eta)

y_predicted_test = predict(w, X_test_tr)
y_predicted_train = predict(w, X_train_tr)

train_accuracy = 100.0 - np.mean(np.abs(y_predicted_train - y_train_tr)*100.0)
test_accuracy = 100.0 - np.mean(np.abs(y_predicted_test-y_test_tr)*100.0)
print(f"Итоговый вектор весов w: {w}")
print(f"Точность на обучающей выборке: {train_accuracy:.3f}")
print(f"Точность на тестовой выборке: {test_accuracy:.3f}")

xl = np.array([[1,1],[-2,2],[-2,2]])*0.9
yt = np.dot(w.T, xl)

colors = ListedColormap(['red', 'blue','green'])
y_x = predict(w,classes[0].T)

plt.title('Log loss')
plt.xlabel('iterations')
plt.ylabel('loss')
plt.plot(range(len(losses)), losses)

plt.figure(figsize=(25, 16))
plt.subplot(1,2,1)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=classes[1], cmap=colors)
plt.grid()
plt.title('True y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.subplot(1,2,2)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=y_x.reshape(-1), cmap=colors)
plt.grid()
plt.title('Predict y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.show()

# print(y_test.shape)
# print(y_predicted_test.shape)
# lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)


#ROC-AUC


X_test_tr_sig = np.vstack((np.ones((1, X_test_tr.shape[1])),X_test_tr))
y_pred_log = Sigmoid(np.dot(w.T, X_test_tr_sig))
N = 30
plt.figure(figsize = (16, 5))
plt.subplot(1,2,1)
plt.plot(y_predicted_test[0,:N], 'r' , label = 'true')
plt.plot(y_test_tr[0,:N], '--', label = "class predict")
plt.legend()

plt.subplot(1,2,2)
plt.plot(y_predicted_test[0,:N], "r", label ="true")
plt.plot(y_pred_log[0,:N], "--", label = "log predict")
plt.legend()

plt.show()
y = pd.DataFrame(y_pred_log[0,:])
y[1] = y_test_tr[0,:]

TPR = []
FPR = []

for i in range (len(y.iloc[:,0])):
  tresholds = y.iloc[i,0]- 0.00000000001
  y_p = y.iloc[:,0]>tresholds
  c = [[np.sum((y.iloc[:,1]== 1) & (y_p == y.iloc[:,1])), np.sum((y.iloc[:,1] ==1) &(y_p != y.iloc[:,1]))],
       [np.sum((y.iloc[:,1] == 0) & (y_p != y.iloc[:,1])), np.sum((y.iloc[:,1] == 0)& (y_p == y.iloc[:,1]))]]
  TP = c[0][0]
  TN = c[1][1]
  FP = c[1][0]
  FN = c[0][1]

  TPR.append(TP/(TP+FN))
  FPR.append(FP/(FP+TN))

AUC_ROC = trapz(TPR, x = FPR, dx = 0.1)

plt.title('ROC curve')
plt.ylim(0, 1.05)
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.grid()
plt.legend('', title = f'AUC_ROC = {AUC_ROC: .3f}', loc="lower right")
plt.plot(FPR,TPR)
plt.show()


#импортированные встроенные метрики
# вопрос: насколько им можно верить? 

lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)

#f1_score
from sklearn.metrics import f1_score
f1= f1_score(y_test,  lr_pred ,  average=None, zero_division="warn")
print(f'cреднее гармоническое точности и полноты f1_score:{f1} ')

#доля правильных ответов, точность, полнота алгоритма 
accuracy = accuracy_score(lr_pred, y_test)
precision = precision_score(lr_pred , y_test)
recall = recall_score(lr_pred , y_test)
print(f'доля правильных ответов алгоритма logR: {accuracy}, точность алгоритма logR:  {precision}, полнота алгоритма logR:  {recall} ')

#матрицa ошибок

cm = metrics.confusion_matrix(y_test, lr_pred)
plt.figure(figsize=(9,9))
sns.heatmap(cm,annot = True, fmt='.3f', linewidth=.5,square=True,cmap='Blues_r')
plt.xlabel('Actual label')
plt.ylabel('Predicted label')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy)
plt.title(all_sample_title,size = 15)
plt.show()


#A receiver operating characteristic curve (ROC curve)
#не уверена, наксолько  верно подправила эту ROC кривую.

y_pred_log_tr = y_pred_log.transpose()

fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_log_tr )
auc = metrics.roc_auc_score(y_test,  y_pred_log_tr )
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('A receiver operating characteristic curve')
plt.legend(loc="lower right")


#the third variant:
# w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 0.1
# n_iterations = 5000
# eta = 0.005
# threshold = 0.5
    
def Sigmoid(x):
    return 1/(1 + np.exp(-x))


#making some data
classes = datasets.make_classification(n_samples=10000, n_features=2, n_informative=2,
                                       n_redundant=0, n_classes=2, random_state=42)


np.random.seed(42)
shuffle_index = np.random.permutation(classes[0].shape[0])
X_shuffled, y_shuffled = classes[0][shuffle_index], classes[1][shuffle_index]
train_proportion = 0.7
train_test_cut = int(len(classes[0]) * train_proportion)

X_train, X_test, y_train, y_test = \
    X_shuffled[:train_test_cut], \
    X_shuffled[train_test_cut:], \
    y_shuffled[:train_test_cut], \
    y_shuffled[train_test_cut:]
X_train_tr = X_train.transpose()
y_train_tr = y_train.reshape(1, y_train.shape[0])
X_test_tr = X_test.transpose()
y_test_tr = y_test.reshape(1, y_test.shape[0])


ss_train = StandardScaler()
X_train = ss_train.fit_transform(X_train)

ss_test = StandardScaler()
X_test = ss_test.fit_transform(X_test)



def log_loss(w, X, y):
    m = X.shape[1]
    A = Sigmoid(np.dot(w.T, X))
    loss = -1.0 / m * np.sum(y * np.log(A) + (1 - y) * np.log(1 - A))
    loss = np.squeeze(loss)
    grad = 1.0 / m * np.dot(X, (A - y).T)
    
    return loss, grad

def optimize(w, X, y, n_iterations, eta):
    losses = []
    X = np.vstack((np.ones((1,X.shape[1])),X))
    for i in range(n_iterations):        
        loss, grad = log_loss(w, X, y)
        w = w - eta * grad
        losses.append(loss)
        
    return w, losses


def predict(w, X):
    
    m = X.shape[1]
    X = np.vstack((np.ones((1,X.shape[1])),X))

    y_predicted = np.zeros((1, m))
    w = w.reshape(X.shape[0], 1)
    A = Sigmoid(np.dot(w.T, X))
    
    for i in range(A.shape[1]):
        if (A[:,i] > 0.5): 
            y_predicted[:, i] = 1
        elif (A[:,i] <= 0.5):
            y_predicted[:, i] = 0
    return y_predicted


w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 0.1

n_iterations = 5000
eta = 0.005

w, losses = optimize(w0, X_train_tr, y_train_tr, n_iterations, eta)

y_predicted_test = predict(w, X_test_tr)
y_predicted_train = predict(w, X_train_tr)

train_accuracy = 100.0 - np.mean(np.abs(y_predicted_train - y_train_tr)*100.0)
test_accuracy = 100.0 - np.mean(np.abs(y_predicted_test-y_test_tr)*100.0)
print(f"Итоговый вектор весов w: {w}")
print(f"Точность на обучающей выборке: {train_accuracy:.3f}")
print(f"Точность на тестовой выборке: {test_accuracy:.3f}")

xl = np.array([[1,1],[-2,2],[-2,2]])*0.9
yt = np.dot(w.T, xl)

colors = ListedColormap(['red', 'blue','green'])
y_x = predict(w,classes[0].T)

plt.title('Log loss')
plt.xlabel('iterations')
plt.ylabel('loss')
plt.plot(range(len(losses)), losses)

plt.figure(figsize=(25, 16))
plt.subplot(1,2,1)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=classes[1], cmap=colors)
plt.grid()
plt.title('True y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.subplot(1,2,2)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=y_x.reshape(-1), cmap=colors)
plt.grid()
plt.title('Predict y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.show()

# print(y_test.shape)
# print(y_predicted_test.shape)
# lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)


#ROC-AUC


X_test_tr_sig = np.vstack((np.ones((1, X_test_tr.shape[1])),X_test_tr))
y_pred_log = Sigmoid(np.dot(w.T, X_test_tr_sig))
N = 30
plt.figure(figsize = (16, 5))
plt.subplot(1,2,1)
plt.plot(y_predicted_test[0,:N], 'r' , label = 'true')
plt.plot(y_test_tr[0,:N], '--', label = "class predict")
plt.legend()

plt.subplot(1,2,2)
plt.plot(y_predicted_test[0,:N], "r", label ="true")
plt.plot(y_pred_log[0,:N], "--", label = "log predict")
plt.legend()

plt.show()
y = pd.DataFrame(y_pred_log[0,:])
y[1] = y_test_tr[0,:]

TPR = []
FPR = []

for i in range (len(y.iloc[:,0])):
  tresholds = y.iloc[i,0]- 0.00000000001
  y_p = y.iloc[:,0]>tresholds
  c = [[np.sum((y.iloc[:,1]== 1) & (y_p == y.iloc[:,1])), np.sum((y.iloc[:,1] ==1) &(y_p != y.iloc[:,1]))],
       [np.sum((y.iloc[:,1] == 0) & (y_p != y.iloc[:,1])), np.sum((y.iloc[:,1] == 0)& (y_p == y.iloc[:,1]))]]
  TP = c[0][0]
  TN = c[1][1]
  FP = c[1][0]
  FN = c[0][1]

  TPR.append(TP/(TP+FN))
  FPR.append(FP/(FP+TN))

AUC_ROC = trapz(TPR, x = FPR, dx = 0.1)

plt.title('ROC curve')
plt.ylim(0, 1.05)
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.grid()
plt.legend('', title = f'AUC_ROC = {AUC_ROC:.3f}', loc="lower right")
plt.plot(FPR,TPR)
plt.show()



#импортированные встроенные метрики
# вопрос: насколько им можно верить?

lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)

#f1_score
from sklearn.metrics import f1_score
f1= f1_score(y_test,  lr_pred ,  average=None, zero_division="warn")
print(f'cреднее гармоническое точности и полноты f1_score:{f1} ')

#доля правильных ответов, точность, полнота алгоритма 
accuracy = accuracy_score(lr_pred, y_test)

precision = precision_score(lr_pred , y_test)
recall = recall_score(lr_pred , y_test)
print(f'доля правильных ответов алгоритма logR: {accuracy}, точность алгоритма logR:  {precision}, полнота алгоритма logR:  {recall} ')

#матрицa ошибок

cm = metrics.confusion_matrix(y_test, lr_pred)
plt.figure(figsize=(9,9))
sns.heatmap(cm,annot = True, fmt='.3f', linewidth=.5,square=True,cmap='Blues_r')
plt.xlabel('Actual label')
plt.ylabel('Predicted label')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy)
plt.title(all_sample_title,size = 15)
plt.show()


#A receiver operating characteristic curve (ROC curve)
#не уверена, наксолько  верно подправила эту ROC кривую.

y_pred_log_tr = y_pred_log.transpose()

fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_log_tr )
auc = metrics.roc_auc_score(y_test,  y_pred_log_tr )
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('A receiver operating characteristic curve')
plt.legend(loc="lower right")




# the fourth variant:

# w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 0.5
# n_iterations = 10000
# eta = 0.005
# threshold = 0.5


def Sigmoid(x):
    return 1/(1 + np.exp(-x))


#making some data
classes = datasets.make_classification(n_samples=10000, n_features=2, n_informative=2,
                                       n_redundant=0, n_classes=2, random_state=42)


np.random.seed(42)
shuffle_index = np.random.permutation(classes[0].shape[0])
X_shuffled, y_shuffled = classes[0][shuffle_index], classes[1][shuffle_index]
train_proportion = 0.7
train_test_cut = int(len(classes[0]) * train_proportion)

X_train, X_test, y_train, y_test = \
    X_shuffled[:train_test_cut], \
    X_shuffled[train_test_cut:], \
    y_shuffled[:train_test_cut], \
    y_shuffled[train_test_cut:]
X_train_tr = X_train.transpose()
y_train_tr = y_train.reshape(1, y_train.shape[0])
X_test_tr = X_test.transpose()
y_test_tr = y_test.reshape(1, y_test.shape[0])


ss_train = StandardScaler()
X_train = ss_train.fit_transform(X_train)

ss_test = StandardScaler()
X_test = ss_test.fit_transform(X_test)



def log_loss(w, X, y):
    m = X.shape[1]
    A = Sigmoid(np.dot(w.T, X))
    loss = -1.0 / m * np.sum(y * np.log(A) + (1 - y) * np.log(1 - A))
    loss = np.squeeze(loss)
    grad = 1.0 / m * np.dot(X, (A - y).T)
    
    return loss, grad

def optimize(w, X, y, n_iterations, eta):
    losses = []
    X = np.vstack((np.ones((1,X.shape[1])),X))
    for i in range(n_iterations):        
        loss, grad = log_loss(w, X, y)
        w = w - eta * grad
        losses.append(loss)
        
    return w, losses


def predict(w, X):
    
    m = X.shape[1]
    X = np.vstack((np.ones((1,X.shape[1])),X))

    y_predicted = np.zeros((1, m))
    w = w.reshape(X.shape[0], 1)
    A = Sigmoid(np.dot(w.T, X))
    
    for i in range(A.shape[1]):
        if (A[:,i] > 0.5): 
            y_predicted[:, i] = 1
        elif (A[:,i] <= 0.5):
            y_predicted[:, i] = 0
    return y_predicted


w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 0.5

n_iterations = 10000
eta = 0.005

w, losses = optimize(w0, X_train_tr, y_train_tr, n_iterations, eta)

y_predicted_test = predict(w, X_test_tr)
y_predicted_train = predict(w, X_train_tr)

train_accuracy = 100.0 - np.mean(np.abs(y_predicted_train - y_train_tr)*100.0)
test_accuracy = 100.0 - np.mean(np.abs(y_predicted_test-y_test_tr)*100.0)
print(f"Итоговый вектор весов w: {w}")
print(f"Точность на обучающей выборке: {train_accuracy:.3f}")
print(f"Точность на тестовой выборке: {test_accuracy:.3f}")

xl = np.array([[1,1],[-2,2],[-2,2]])*0.9
yt = np.dot(w.T, xl)

colors = ListedColormap(['red', 'blue','green'])
y_x = predict(w,classes[0].T)

plt.title('Log loss')
plt.xlabel('iterations')
plt.ylabel('loss')
plt.plot(range(len(losses)), losses)

plt.figure(figsize=(25, 16))
plt.subplot(1,2,1)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=classes[1], cmap=colors)
plt.grid()
plt.title('True y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.subplot(1,2,2)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=y_x.reshape(-1), cmap=colors)
plt.grid()
plt.title('Predict y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.show()

# print(y_test.shape)
# print(y_predicted_test.shape)
lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)


#ROC-AUC


X_test_tr_sig = np.vstack((np.ones((1, X_test_tr.shape[1])),X_test_tr))
y_pred_log = Sigmoid(np.dot(w.T, X_test_tr_sig))
N = 30
plt.figure(figsize = (16, 5))
plt.subplot(1,2,1)
plt.plot(y_predicted_test[0,:N], 'r' , label = 'true')
plt.plot(y_test_tr[0,:N], '--', label = "class predict")
plt.legend()

plt.subplot(1,2,2)
plt.plot(y_predicted_test[0,:N], "r", label ="true")
plt.plot(y_pred_log[0,:N], "--", label = "log predict")
plt.legend()

plt.show()
y = pd.DataFrame(y_pred_log[0,:])
y[1] = y_test_tr[0,:]

TPR = []
FPR = []

for i in range (len(y.iloc[:,0])):
  tresholds = y.iloc[i,0]- 0.00000000001
  y_p = y.iloc[:,0]>tresholds
  c = [[np.sum((y.iloc[:,1]== 1) & (y_p == y.iloc[:,1])), np.sum((y.iloc[:,1] ==1) &(y_p != y.iloc[:,1]))],
       [np.sum((y.iloc[:,1] == 0) & (y_p != y.iloc[:,1])), np.sum((y.iloc[:,1] == 0)& (y_p == y.iloc[:,1]))]]
  TP = c[0][0]
  TN = c[1][1]
  FP = c[1][0]
  FN = c[0][1]

  TPR.append(TP/(TP+FN))
  FPR.append(FP/(FP+TN))

AUC_ROC = trapz(TPR, x = FPR, dx = 0.1)

plt.title('ROC curve')
plt.ylim(0, 1.05)
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.grid()
plt.legend('', title = f'AUC_ROC = {AUC_ROC:.3f}', loc="lower right")
plt.plot(FPR,TPR)
plt.show()



#импортированные встроенные метрики
# вопрос: насколько им можно верить?

lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)

#f1_score
from sklearn.metrics import f1_score
f1= f1_score(y_test,  lr_pred ,  average=None, zero_division="warn")
print(f'cреднее гармоническое точности и полноты f1_score:{f1} ')

#доля правильных ответов, точность, полнота алгоритма 
accuracy = accuracy_score(lr_pred, y_test)
precision = precision_score(lr_pred , y_test)
recall = recall_score(lr_pred , y_test)
print(f'доля правильных ответов алгоритма logR: {accuracy}, точность алгоритма logR:  {precision}, полнота алгоритма logR:  {recall} ')

#матрицa ошибок

cm = metrics.confusion_matrix(y_test, lr_pred)
plt.figure(figsize=(9,9))
sns.heatmap(cm,annot = True, fmt='.3f', linewidth=.5,square=True,cmap='Blues_r')
plt.xlabel('Actual label')
plt.ylabel('Predicted label')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy)
plt.title(all_sample_title,size = 15)
plt.show()


#A receiver operating characteristic curve (ROC curve)
#не уверена, наксолько  верно подправила эту ROC кривую.

y_pred_log_tr = y_pred_log.transpose()

fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_log_tr )
auc = metrics.roc_auc_score(y_test,  y_pred_log_tr )
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('A receiver operating characteristic curve')
plt.legend(loc="lower right")

# the fifth variant:

# w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 0.5
# n_iterations = 10000
# eta = 0.5
# threshold = 0.5



def Sigmoid(x):
    return 1/(1 + np.exp(-x))


#making some data
classes = datasets.make_classification(n_samples=10000, n_features=2, n_informative=2,
                                       n_redundant=0, n_classes=2, random_state=42)


np.random.seed(42)
shuffle_index = np.random.permutation(classes[0].shape[0])
X_shuffled, y_shuffled = classes[0][shuffle_index], classes[1][shuffle_index]
train_proportion = 0.7
train_test_cut = int(len(classes[0]) * train_proportion)

X_train, X_test, y_train, y_test = \
    X_shuffled[:train_test_cut], \
    X_shuffled[train_test_cut:], \
    y_shuffled[:train_test_cut], \
    y_shuffled[train_test_cut:]
X_train_tr = X_train.transpose()
y_train_tr = y_train.reshape(1, y_train.shape[0])
X_test_tr = X_test.transpose()
y_test_tr = y_test.reshape(1, y_test.shape[0])


ss_train = StandardScaler()
X_train = ss_train.fit_transform(X_train)

ss_test = StandardScaler()
X_test = ss_test.fit_transform(X_test)



def log_loss(w, X, y):
    m = X.shape[1]
    A = Sigmoid(np.dot(w.T, X))
    loss = -1.0 / m * np.sum(y * np.log(A) + (1 - y) * np.log(1 - A))
    loss = np.squeeze(loss)
    grad = 1.0 / m * np.dot(X, (A - y).T)
    
    return loss, grad

def optimize(w, X, y, n_iterations, eta):
    losses = []
    X = np.vstack((np.ones((1,X.shape[1])),X))
    for i in range(n_iterations):        
        loss, grad = log_loss(w, X, y)
        w = w - eta * grad
        losses.append(loss)
        
    return w, losses


def predict(w, X):
    
    m = X.shape[1]
    X = np.vstack((np.ones((1,X.shape[1])),X))

    y_predicted = np.zeros((1, m))
    w = w.reshape(X.shape[0], 1)
    A = Sigmoid(np.dot(w.T, X))
    
    for i in range(A.shape[1]):
        if (A[:,i] > 0.5): 
            y_predicted[:, i] = 1
        elif (A[:,i] <= 0.5):
            y_predicted[:, i] = 0
    return y_predicted


w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 0.5

n_iterations = 10000
eta = 0.5

w, losses = optimize(w0, X_train_tr, y_train_tr, n_iterations, eta)

y_predicted_test = predict(w, X_test_tr)
y_predicted_train = predict(w, X_train_tr)

train_accuracy = 100.0 - np.mean(np.abs(y_predicted_train - y_train_tr)*100.0)
test_accuracy = 100.0 - np.mean(np.abs(y_predicted_test-y_test_tr)*100.0)
print(f"Итоговый вектор весов w: {w}")
print(f"Точность на обучающей выборке: {train_accuracy:.3f}")
print(f"Точность на тестовой выборке: {test_accuracy:.3f}")

xl = np.array([[1,1],[-2,2],[-2,2]])*0.9
yt = np.dot(w.T, xl)

colors = ListedColormap(['red', 'blue','green'])
y_x = predict(w,classes[0].T)

plt.title('Log loss')
plt.xlabel('iterations')
plt.ylabel('loss')
plt.plot(range(len(losses)), losses)

plt.figure(figsize=(25, 16))
plt.subplot(1,2,1)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=classes[1], cmap=colors)
plt.grid()
plt.title('True y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.subplot(1,2,2)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=y_x.reshape(-1), cmap=colors)
plt.grid()
plt.title('Predict y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.show()

# print(y_test.shape)
# print(y_predicted_test.shape)
lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)


#ROC-AUC


X_test_tr_sig = np.vstack((np.ones((1, X_test_tr.shape[1])),X_test_tr))
y_pred_log = Sigmoid(np.dot(w.T, X_test_tr_sig))
N = 30
plt.figure(figsize = (16, 5))
plt.subplot(1,2,1)
plt.plot(y_predicted_test[0,:N], 'r' , label = 'true')
plt.plot(y_test_tr[0,:N], '--', label = "class predict")
plt.legend()

plt.subplot(1,2,2)
plt.plot(y_predicted_test[0,:N], "r", label ="true")
plt.plot(y_pred_log[0,:N], "--", label = "log predict")
plt.legend()

plt.show()
y = pd.DataFrame(y_pred_log[0,:])
y[1] = y_test_tr[0,:]

TPR = []
FPR = []

for i in range (len(y.iloc[:,0])):
  tresholds = y.iloc[i,0]- 0.00000000001
  y_p = y.iloc[:,0]>tresholds
  c = [[np.sum((y.iloc[:,1]== 1) & (y_p == y.iloc[:,1])), np.sum((y.iloc[:,1] ==1) &(y_p != y.iloc[:,1]))],
       [np.sum((y.iloc[:,1] == 0) & (y_p != y.iloc[:,1])), np.sum((y.iloc[:,1] == 0)& (y_p == y.iloc[:,1]))]]
  TP = c[0][0]
  TN = c[1][1]
  FP = c[1][0]
  FN = c[0][1]

  TPR.append(TP/(TP+FN))
  FPR.append(FP/(FP+TN))

AUC_ROC = trapz(TPR, x = FPR, dx = 1)

plt.title('ROC curve')
plt.ylim(0, 1.05)
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.grid()
plt.legend('', title = f'AUC_ROC = {AUC_ROC:.3f}', loc="lower right")
plt.plot(FPR,TPR)
plt.show()

#импортированные встроенные метрики
# вопрос: насколько им можно верить?

lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)

#f1_score
from sklearn.metrics import f1_score
f1= f1_score(y_test,  lr_pred ,  average=None, zero_division="warn")
print(f'cреднее гармоническое точности и полноты f1_score:{f1} ')

#доля правильных ответов, точность, полнота алгоритма 
accuracy = accuracy_score(lr_pred, y_test)
precision = precision_score(lr_pred , y_test)
recall = recall_score(lr_pred , y_test)
print(f'доля правильных ответов алгоритма logR: {accuracy}, точность алгоритма logR:  {precision}, полнота алгоритма logR:  {recall} ')

#матрицa ошибок

cm = metrics.confusion_matrix(y_test, lr_pred)
plt.figure(figsize=(9,9))
sns.heatmap(cm,annot = True, fmt='.3f', linewidth=.5,square=True,cmap='Blues_r')
plt.xlabel('Actual label')
plt.ylabel('Predicted label')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy)
plt.title(all_sample_title,size = 15)
plt.show()


#A receiver operating characteristic curve (ROC curve)
#не уверена, наксолько  верно подправила эту ROC кривую.

y_pred_log_tr = y_pred_log.transpose()

fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_log_tr )
auc = metrics.roc_auc_score(y_test,  y_pred_log_tr )
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('A receiver operating characteristic curve')
plt.legend(loc="lower right")

 # the sixth variant:

# w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 0.5
# n_iterations = 10000
# eta = 0.05
#threshold = 0.3

def Sigmoid(x):
    return 1/(1 + np.exp(-x))


#making some data
classes = datasets.make_classification(n_samples=10000, n_features=2, n_informative=2,
                                       n_redundant=0, n_classes=2, random_state=42)


np.random.seed(42)
shuffle_index = np.random.permutation(classes[0].shape[0])
X_shuffled, y_shuffled = classes[0][shuffle_index], classes[1][shuffle_index]
train_proportion = 0.7
train_test_cut = int(len(classes[0]) * train_proportion)

X_train, X_test, y_train, y_test = \
    X_shuffled[:train_test_cut], \
    X_shuffled[train_test_cut:], \
    y_shuffled[:train_test_cut], \
    y_shuffled[train_test_cut:]
X_train_tr = X_train.transpose()
y_train_tr = y_train.reshape(1, y_train.shape[0])
X_test_tr = X_test.transpose()
y_test_tr = y_test.reshape(1, y_test.shape[0])


ss_train = StandardScaler()
X_train = ss_train.fit_transform(X_train)

ss_test = StandardScaler()
X_test = ss_test.fit_transform(X_test)



def log_loss(w, X, y):
    m = X.shape[1]
    A = Sigmoid(np.dot(w.T, X))
    loss = -1.0 / m * np.sum(y * np.log(A) + (1 - y) * np.log(1 - A))
    loss = np.squeeze(loss)
    grad = 1.0 / m * np.dot(X, (A - y).T)
    
    return loss, grad

def optimize(w, X, y, n_iterations, eta):
    losses = []
    X = np.vstack((np.ones((1,X.shape[1])),X))
    for i in range(n_iterations):        
        loss, grad = log_loss(w, X, y)
        w = w - eta * grad
        losses.append(loss)
        
    return w, losses


def predict(w, X):
    
    m = X.shape[1]
    X = np.vstack((np.ones((1,X.shape[1])),X))

    y_predicted = np.zeros((1, m))
    w = w.reshape(X.shape[0], 1)
    A = Sigmoid(np.dot(w.T, X))
    
    for i in range(A.shape[1]):
        if (A[:,i] > 0.3): 
            y_predicted[:, i] = 1
        elif (A[:,i] <= 0.3):
            y_predicted[:, i] = 0
    return y_predicted


w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 0.5

n_iterations = 10000
eta = 0.05

w, losses = optimize(w0, X_train_tr, y_train_tr, n_iterations, eta)

y_predicted_test = predict(w, X_test_tr)
y_predicted_train = predict(w, X_train_tr)

train_accuracy = 100.0 - np.mean(np.abs(y_predicted_train - y_train_tr)*100.0)
test_accuracy = 100.0 - np.mean(np.abs(y_predicted_test-y_test_tr)*100.0)
print(f"Итоговый вектор весов w: {w}")
print(f"Точность на обучающей выборке: {train_accuracy:.3f}")
print(f"Точность на тестовой выборке: {test_accuracy:.3f}")

xl = np.array([[1,1],[-2,2],[-2,2]])*0.9
yt = np.dot(w.T, xl)

colors = ListedColormap(['red', 'blue','green'])
y_x = predict(w,classes[0].T)

plt.title('Log loss')
plt.xlabel('iterations')
plt.ylabel('loss')
plt.plot(range(len(losses)), losses)

plt.figure(figsize=(25, 16))
plt.subplot(1,2,1)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=classes[1], cmap=colors)
plt.grid()
plt.title('True y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.subplot(1,2,2)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=y_x.reshape(-1), cmap=colors)
plt.grid()
plt.title('Predict y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.show()

# print(y_test.shape)
# print(y_predicted_test.shape)
# lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)


#ROC-AUC


X_test_tr_sig = np.vstack((np.ones((1, X_test_tr.shape[1])),X_test_tr))
y_pred_log = Sigmoid(np.dot(w.T, X_test_tr_sig))
N = 50
plt.figure(figsize = (16, 5))
plt.subplot(1,2,1)
plt.plot(y_predicted_test[0,:N], 'r' , label = 'true')
plt.plot(y_test_tr[0,:N], '--', label = "class predict")
plt.legend()

plt.subplot(1,2,2)
plt.plot(y_predicted_test[0,:N], "r", label ="true")
plt.plot(y_pred_log[0,:N], "--", label = "log predict")
plt.legend()

plt.show()
y = pd.DataFrame(y_pred_log[0,:])
y[1] = y_test_tr[0,:]

TPR = []
FPR = []

for i in range (len(y.iloc[:,0])):
  tresholds = y.iloc[i,0]- 0.00000000001
  y_p = y.iloc[:,0]>tresholds
  c = [[np.sum((y.iloc[:,1]== 1) & (y_p == y.iloc[:,1])), np.sum((y.iloc[:,1] ==1) &(y_p != y.iloc[:,1]))],
       [np.sum((y.iloc[:,1] == 0) & (y_p != y.iloc[:,1])), np.sum((y.iloc[:,1] == 0)& (y_p == y.iloc[:,1]))]]
  TP = c[0][0]
  TN = c[1][1]
  FP = c[1][0]
  FN = c[0][1]

  TPR.append(TP/(TP+FN))
  FPR.append(FP/(FP+TN))

AUC_ROC = trapz(TPR, x = FPR, dx = 0.1)

plt.title('ROC curve')
plt.ylim(0, 1.05)
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.grid()
plt.legend('', title = f'AUC_ROC = {AUC_ROC:.3f}', loc="lower right")
plt.plot(FPR,TPR)
plt.show()



#импортированные встроенные метрики
# вопрос: насколько им можно верить?

lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)

#f1_score
from sklearn.metrics import f1_score
f1= f1_score(y_test,  lr_pred ,  average=None, zero_division="warn")
print(f'cреднее гармоническое точности и полноты f1_score:{f1} ')

#доля правильных ответов, точность, полнота алгоритма 
accuracy = accuracy_score(lr_pred, y_test)
precision = precision_score(lr_pred , y_test)
recall = recall_score(lr_pred , y_test)
print(f'доля правильных ответов алгоритма logR: {accuracy}, точность алгоритма logR:  {precision}, полнота алгоритма logR:  {recall} ')

#матрицa ошибок

cm = metrics.confusion_matrix(y_test, lr_pred)
plt.figure(figsize=(9,9))
sns.heatmap(cm,annot = True, fmt='.3f', linewidth=.5,square=True,cmap='Blues_r')
plt.xlabel('Actual label')
plt.ylabel('Predicted label')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy)
plt.title(all_sample_title,size = 15)
plt.show()


#A receiver operating characteristic curve (ROC curve)
#не уверена, наксолько  верно подправила эту ROC кривую.

y_pred_log_tr = y_pred_log.transpose()

fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_log_tr )
auc = metrics.roc_auc_score(y_test,  y_pred_log_tr )
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('A receiver operating characteristic curve')
plt.legend(loc="lower right")


 # the seventh variant:
# w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 0.5
# n_iterations = 10000
# eta = 0.05
#threshold = 0.7

def Sigmoid(x):
    return 1/(1 + np.exp(-x))


#making some data
classes = datasets.make_classification(n_samples=10000, n_features=2, n_informative=2,
                                       n_redundant=0, n_classes=2, random_state=42)


np.random.seed(42)
shuffle_index = np.random.permutation(classes[0].shape[0])
X_shuffled, y_shuffled = classes[0][shuffle_index], classes[1][shuffle_index]
train_proportion = 0.7
train_test_cut = int(len(classes[0]) * train_proportion)

X_train, X_test, y_train, y_test = \
    X_shuffled[:train_test_cut], \
    X_shuffled[train_test_cut:], \
    y_shuffled[:train_test_cut], \
    y_shuffled[train_test_cut:]
X_train_tr = X_train.transpose()
y_train_tr = y_train.reshape(1, y_train.shape[0])
X_test_tr = X_test.transpose()
y_test_tr = y_test.reshape(1, y_test.shape[0])


ss_train = StandardScaler()
X_train = ss_train.fit_transform(X_train)

ss_test = StandardScaler()
X_test = ss_test.fit_transform(X_test)



def log_loss(w, X, y):
    m = X.shape[1]
    A = Sigmoid(np.dot(w.T, X))
    loss = -1.0 / m * np.sum(y * np.log(A) + (1 - y) * np.log(1 - A))
    loss = np.squeeze(loss)
    grad = 1.0 / m * np.dot(X, (A - y).T)
    
    return loss, grad

def optimize(w, X, y, n_iterations, eta):
    losses = []
    X = np.vstack((np.ones((1,X.shape[1])),X))
    for i in range(n_iterations):        
        loss, grad = log_loss(w, X, y)
        w = w - eta * grad
        losses.append(loss)
        
    return w, losses


def predict(w, X):
    
    m = X.shape[1]
    X = np.vstack((np.ones((1,X.shape[1])),X))

    y_predicted = np.zeros((1, m))
    w = w.reshape(X.shape[0], 1)
    A = Sigmoid(np.dot(w.T, X))
    
    for i in range(A.shape[1]):
        if (A[:,i] > 0.7): 
            y_predicted[:, i] = 1
        elif (A[:,i] <= 0.7):
            y_predicted[:, i] = 0
    return y_predicted


w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 0.5

n_iterations = 10000
eta = 0.05

w, losses = optimize(w0, X_train_tr, y_train_tr, n_iterations, eta)

y_predicted_test = predict(w, X_test_tr)
y_predicted_train = predict(w, X_train_tr)

train_accuracy = 100.0 - np.mean(np.abs(y_predicted_train - y_train_tr)*100.0)
test_accuracy = 100.0 - np.mean(np.abs(y_predicted_test-y_test_tr)*100.0)
print(f"Итоговый вектор весов w: {w}")
print(f"Точность на обучающей выборке: {train_accuracy:.3f}")
print(f"Точность на тестовой выборке: {test_accuracy:.3f}")

xl = np.array([[1,1],[-2,2],[-2,2]])*0.9
yt = np.dot(w.T, xl)

colors = ListedColormap(['red', 'blue','green'])
y_x = predict(w,classes[0].T)

plt.title('Log loss')
plt.xlabel('iterations')
plt.ylabel('loss')
plt.plot(range(len(losses)), losses)

plt.figure(figsize=(25, 16))
plt.subplot(1,2,1)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=classes[1], cmap=colors)
plt.grid()
plt.title('True y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.subplot(1,2,2)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=y_x.reshape(-1), cmap=colors)
plt.grid()
plt.title('Predict y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.show()

# print(y_test.shape)
# print(y_predicted_test.shape)
# lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)


#ROC-AUC


X_test_tr_sig = np.vstack((np.ones((1, X_test_tr.shape[1])),X_test_tr))
y_pred_log = Sigmoid(np.dot(w.T, X_test_tr_sig))
N = 50
plt.figure(figsize = (16, 5))
plt.subplot(1,2,1)
plt.plot(y_predicted_test[0,:N], 'r' , label = 'true')
plt.plot(y_test_tr[0,:N], '--', label = "class predict")
plt.legend()

plt.subplot(1,2,2)
plt.plot(y_predicted_test[0,:N], "r", label ="true")
plt.plot(y_pred_log[0,:N], "--", label = "log predict")
plt.legend()

plt.show()
y = pd.DataFrame(y_pred_log[0,:])
y[1] = y_test_tr[0,:]

TPR = []
FPR = []

for i in range (len(y.iloc[:,0])):
  tresholds = y.iloc[i,0]- 0.00000000001
  y_p = y.iloc[:,0]>tresholds
  c = [[np.sum((y.iloc[:,1]== 1) & (y_p == y.iloc[:,1])), np.sum((y.iloc[:,1] ==1) &(y_p != y.iloc[:,1]))],
       [np.sum((y.iloc[:,1] == 0) & (y_p != y.iloc[:,1])), np.sum((y.iloc[:,1] == 0)& (y_p == y.iloc[:,1]))]]
  TP = c[0][0]
  TN = c[1][1]
  FP = c[1][0]
  FN = c[0][1]

  TPR.append(TP/(TP+FN))
  FPR.append(FP/(FP+TN))

AUC_ROC = trapz(TPR, x = FPR, dx = 0.1)

plt.title('ROC curve')
plt.ylim(0, 1.05)
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.grid()
plt.legend('', title = f'AUC_ROC = {AUC_ROC:.3f}', loc="lower right")
plt.plot(FPR,TPR)
plt.show()



#импортированные встроенные метрики
# вопрос: насколько им можно верить?

lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)

#f1_score
from sklearn.metrics import f1_score
f1= f1_score(y_test,  lr_pred ,  average=None, zero_division="warn")
print(f'cреднее гармоническое точности и полноты f1_score:{f1} ')

#доля правильных ответов, точность, полнота алгоритма 
accuracy = accuracy_score(lr_pred, y_test)
precision = precision_score(lr_pred , y_test)
recall = recall_score(lr_pred , y_test)
print(f'доля правильных ответов алгоритма logR: {accuracy}, точность алгоритма logR:  {precision}, полнота алгоритма logR:  {recall} ')

#матрицa ошибок

cm = metrics.confusion_matrix(y_test, lr_pred)
plt.figure(figsize=(9,9))
sns.heatmap(cm,annot = True, fmt='.3f', linewidth=.5,square=True,cmap='Blues_r')
plt.xlabel('Actual label')
plt.ylabel('Predicted label')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy)
plt.title(all_sample_title,size = 15)
plt.show()


#A receiver operating characteristic curve (ROC curve)
#не уверена, наксолько  верно подправила эту ROC кривую.

y_pred_log_tr = y_pred_log.transpose()

fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_log_tr )
auc = metrics.roc_auc_score(y_test,  y_pred_log_tr )
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('A receiver operating characteristic curve')
plt.legend(loc="lower right")


# the eighth variant:
# w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 0.5
# n_iterations = 10000
# eta = 0.05
#threshold = 0.5

def Sigmoid(x):
    return 1/(1 + np.exp(-x))


#making some data
classes = datasets.make_classification(n_samples=10000, n_features=2, n_informative=2,
                                       n_redundant=0, n_classes=2, random_state=42)


np.random.seed(42)
shuffle_index = np.random.permutation(classes[0].shape[0])
X_shuffled, y_shuffled = classes[0][shuffle_index], classes[1][shuffle_index]
train_proportion = 0.7
train_test_cut = int(len(classes[0]) * train_proportion)

X_train, X_test, y_train, y_test = \
    X_shuffled[:train_test_cut], \
    X_shuffled[train_test_cut:], \
    y_shuffled[:train_test_cut], \
    y_shuffled[train_test_cut:]
X_train_tr = X_train.transpose()
y_train_tr = y_train.reshape(1, y_train.shape[0])
X_test_tr = X_test.transpose()
y_test_tr = y_test.reshape(1, y_test.shape[0])


ss_train = StandardScaler()
X_train = ss_train.fit_transform(X_train)

ss_test = StandardScaler()
X_test = ss_test.fit_transform(X_test)



def log_loss(w, X, y):
    m = X.shape[1]
    A = Sigmoid(np.dot(w.T, X))
    loss = -1.0 / m * np.sum(y * np.log(A) + (1 - y) * np.log(1 - A))
    loss = np.squeeze(loss)
    grad = 1.0 / m * np.dot(X, (A - y).T)
    
    return loss, grad

def optimize(w, X, y, n_iterations, eta):
    losses = []
    X = np.vstack((np.ones((1,X.shape[1])),X))
    for i in range(n_iterations):        
        loss, grad = log_loss(w, X, y)
        w = w - eta * grad
        losses.append(loss)
        
    return w, losses


def predict(w, X):
    
    m = X.shape[1]
    X = np.vstack((np.ones((1,X.shape[1])),X))

    y_predicted = np.zeros((1, m))
    w = w.reshape(X.shape[0], 1)
    A = Sigmoid(np.dot(w.T, X))
    
    for i in range(A.shape[1]):
        if (A[:,i] > 0.5): 
            y_predicted[:, i] = 1
        elif (A[:,i] <= 0.5):
            y_predicted[:, i] = 0
    return y_predicted


w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 0.5

n_iterations = 10000
eta = 0.05

w, losses = optimize(w0, X_train_tr, y_train_tr, n_iterations, eta)

y_predicted_test = predict(w, X_test_tr)
y_predicted_train = predict(w, X_train_tr)

train_accuracy = 100.0 - np.mean(np.abs(y_predicted_train - y_train_tr)*100.0)
test_accuracy = 100.0 - np.mean(np.abs(y_predicted_test-y_test_tr)*100.0)
print(f"Итоговый вектор весов w: {w}")
print(f"Точность на обучающей выборке: {train_accuracy:.3f}")
print(f"Точность на тестовой выборке: {test_accuracy:.3f}")

xl = np.array([[1,1],[-2,2],[-2,2]])*0.9
yt = np.dot(w.T, xl)

colors = ListedColormap(['red', 'blue','green'])
y_x = predict(w,classes[0].T)

plt.title('Log loss')
plt.xlabel('iterations')
plt.ylabel('loss')
plt.plot(range(len(losses)), losses)

plt.figure(figsize=(25, 16))
plt.subplot(1,2,1)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=classes[1], cmap=colors)
plt.grid()
plt.title('True y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.subplot(1,2,2)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=y_x.reshape(-1), cmap=colors)
plt.grid()
plt.title('Predict y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.show()

# print(y_test.shape)
# print(y_predicted_test.shape)
# lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)


#ROC-AUC


X_test_tr_sig = np.vstack((np.ones((1, X_test_tr.shape[1])),X_test_tr))
y_pred_log = Sigmoid(np.dot(w.T, X_test_tr_sig))
N = 50
plt.figure(figsize = (16, 5))
plt.subplot(1,2,1)
plt.plot(y_predicted_test[0,:N], 'r' , label = 'true')
plt.plot(y_test_tr[0,:N], '--', label = "class predict")
plt.legend()

plt.subplot(1,2,2)
plt.plot(y_predicted_test[0,:N], "r", label ="true")
plt.plot(y_pred_log[0,:N], "--", label = "log predict")
plt.legend()

plt.show()
y = pd.DataFrame(y_pred_log[0,:])
y[1] = y_test_tr[0,:]

TPR = []
FPR = []

for i in range (len(y.iloc[:,0])):
  tresholds = y.iloc[i,0]- 0.00000000001
  y_p = y.iloc[:,0]>tresholds
  c = [[np.sum((y.iloc[:,1]== 1) & (y_p == y.iloc[:,1])), np.sum((y.iloc[:,1] ==1) &(y_p != y.iloc[:,1]))],
       [np.sum((y.iloc[:,1] == 0) & (y_p != y.iloc[:,1])), np.sum((y.iloc[:,1] == 0)& (y_p == y.iloc[:,1]))]]
  TP = c[0][0]
  TN = c[1][1]
  FP = c[1][0]
  FN = c[0][1]

  TPR.append(TP/(TP+FN))
  FPR.append(FP/(FP+TN))

AUC_ROC = trapz(TPR, x = FPR, dx = 0.1)

plt.title('ROC curve')
plt.ylim(0, 1.05)
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.grid()
plt.legend('', title = f'AUC_ROC = {AUC_ROC:.3f}', loc="lower right")
plt.plot(FPR,TPR)
plt.show()



#импортированные встроенные метрики
# вопрос: насколько им можно верить?

lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)

#f1_score
from sklearn.metrics import f1_score
f1= f1_score(y_test,  lr_pred ,  average=None, zero_division="warn")
print(f'cреднее гармоническое точности и полноты f1_score:{f1} ')

#доля правильных ответов, точность, полнота алгоритма 
accuracy = accuracy_score(lr_pred, y_test)
precision = precision_score(lr_pred , y_test)
recall = recall_score(lr_pred , y_test)
print(f'доля правильных ответов алгоритма logR: {accuracy}, точность алгоритма logR:  {precision}, полнота алгоритма logR:  {recall} ')

#матрицa ошибок

cm = metrics.confusion_matrix(y_test, lr_pred)
plt.figure(figsize=(9,9))
sns.heatmap(cm,annot = True, fmt='.3f', linewidth=.5,square=True,cmap='Blues_r')
plt.xlabel('Actual label')
plt.ylabel('Predicted label')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy)
plt.title(all_sample_title,size = 15)
plt.show()


#A receiver operating characteristic curve (ROC curve)
#не уверена, наксолько  верно подправила эту ROC кривую.

y_pred_log_tr = y_pred_log.transpose()

fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_log_tr )
auc = metrics.roc_auc_score(y_test,  y_pred_log_tr )
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('A receiver operating characteristic curve')
plt.legend(loc="lower right")


# the ninghth variant:
# w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 0.5
# n_iterations = 10000
# eta = 0.005
#threshold = 0.5

def Sigmoid(x):
    return 1/(1 + np.exp(-x))


#making some data
classes = datasets.make_classification(n_samples=10000, n_features=2, n_informative=2,
                                       n_redundant=0, n_classes=2, random_state=42)


np.random.seed(42)
shuffle_index = np.random.permutation(classes[0].shape[0])
X_shuffled, y_shuffled = classes[0][shuffle_index], classes[1][shuffle_index]
train_proportion = 0.7
train_test_cut = int(len(classes[0]) * train_proportion)

X_train, X_test, y_train, y_test = \
    X_shuffled[:train_test_cut], \
    X_shuffled[train_test_cut:], \
    y_shuffled[:train_test_cut], \
    y_shuffled[train_test_cut:]
X_train_tr = X_train.transpose()
y_train_tr = y_train.reshape(1, y_train.shape[0])
X_test_tr = X_test.transpose()
y_test_tr = y_test.reshape(1, y_test.shape[0])


ss_train = StandardScaler()
X_train = ss_train.fit_transform(X_train)

ss_test = StandardScaler()
X_test = ss_test.fit_transform(X_test)



def log_loss(w, X, y):
    m = X.shape[1]
    A = Sigmoid(np.dot(w.T, X))
    loss = -1.0 / m * np.sum(y * np.log(A) + (1 - y) * np.log(1 - A))
    loss = np.squeeze(loss)
    grad = 1.0 / m * np.dot(X, (A - y).T)
    
    return loss, grad

def optimize(w, X, y, n_iterations, eta):
    losses = []
    X = np.vstack((np.ones((1,X.shape[1])),X))
    for i in range(n_iterations):        
        loss, grad = log_loss(w, X, y)
        w = w - eta * grad
        losses.append(loss)
        
    return w, losses


def predict(w, X):
    
    m = X.shape[1]
    X = np.vstack((np.ones((1,X.shape[1])),X))

    y_predicted = np.zeros((1, m))
    w = w.reshape(X.shape[0], 1)
    A = Sigmoid(np.dot(w.T, X))
    
    for i in range(A.shape[1]):
        if (A[:,i] > 0.5): 
            y_predicted[:, i] = 1
        elif (A[:,i] <= 0.5):
            y_predicted[:, i] = 0
    return y_predicted


w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 0.5

n_iterations = 10000
eta = 0.005

w, losses = optimize(w0, X_train_tr, y_train_tr, n_iterations, eta)

y_predicted_test = predict(w, X_test_tr)
y_predicted_train = predict(w, X_train_tr)

train_accuracy = 100.0 - np.mean(np.abs(y_predicted_train - y_train_tr)*100.0)
test_accuracy = 100.0 - np.mean(np.abs(y_predicted_test-y_test_tr)*100.0)
print(f"Итоговый вектор весов w: {w}")
print(f"Точность на обучающей выборке: {train_accuracy:.3f}")
print(f"Точность на тестовой выборке: {test_accuracy:.3f}")

xl = np.array([[1,1],[-2,2],[-2,2]])*0.9
yt = np.dot(w.T, xl)

colors = ListedColormap(['red', 'blue','green'])
y_x = predict(w,classes[0].T)

plt.title('Log loss')
plt.xlabel('iterations')
plt.ylabel('loss')
plt.plot(range(len(losses)), losses)

plt.figure(figsize=(25, 16))
plt.subplot(1,2,1)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=classes[1], cmap=colors)
plt.grid()
plt.title('True y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.subplot(1,2,2)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=y_x.reshape(-1), cmap=colors)
plt.grid()
plt.title('Predict y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.show()

# print(y_test.shape)
# print(y_predicted_test.shape)
# lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)


#ROC-AUC


X_test_tr_sig = np.vstack((np.ones((1, X_test_tr.shape[1])),X_test_tr))
y_pred_log = Sigmoid(np.dot(w.T, X_test_tr_sig))
N = 50
plt.figure(figsize = (16, 5))
plt.subplot(1,2,1)
plt.plot(y_predicted_test[0,:N], 'r' , label = 'true')
plt.plot(y_test_tr[0,:N], '--', label = "class predict")
plt.legend()

plt.subplot(1,2,2)
plt.plot(y_predicted_test[0,:N], "r", label ="true")
plt.plot(y_pred_log[0,:N], "--", label = "log predict")
plt.legend()

plt.show()
y = pd.DataFrame(y_pred_log[0,:])
y[1] = y_test_tr[0,:]

TPR = []
FPR = []

for i in range (len(y.iloc[:,0])):
  tresholds = y.iloc[i,0]- 0.00000000001
  y_p = y.iloc[:,0]>tresholds
  c = [[np.sum((y.iloc[:,1]== 1) & (y_p == y.iloc[:,1])), np.sum((y.iloc[:,1] ==1) &(y_p != y.iloc[:,1]))],
       [np.sum((y.iloc[:,1] == 0) & (y_p != y.iloc[:,1])), np.sum((y.iloc[:,1] == 0)& (y_p == y.iloc[:,1]))]]
  TP = c[0][0]
  TN = c[1][1]
  FP = c[1][0]
  FN = c[0][1]

  TPR.append(TP/(TP+FN))
  FPR.append(FP/(FP+TN))

AUC_ROC = trapz(TPR, x = FPR, dx = 0.1)

plt.title('ROC curve')
plt.ylim(0, 1.05)
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.grid()
plt.legend('', title = f'AUC_ROC = {AUC_ROC:.3f}', loc="lower right")
plt.plot(FPR,TPR)
plt.show()



#импортированные встроенные метрики
# вопрос: насколько им можно верить?

lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)

#f1_score
from sklearn.metrics import f1_score
f1= f1_score(y_test,  lr_pred ,  average=None, zero_division="warn")
print(f'cреднее гармоническое точности и полноты f1_score:{f1} ')

#доля правильных ответов, точность, полнота алгоритма 
accuracy = accuracy_score(lr_pred, y_test)
precision = precision_score(lr_pred , y_test)
recall = recall_score(lr_pred , y_test)
print(f'доля правильных ответов алгоритма logR: {accuracy}, точность алгоритма logR:  {precision}, полнота алгоритма logR:  {recall} ')

#матрицa ошибок

cm = metrics.confusion_matrix(y_test, lr_pred)
plt.figure(figsize=(9,9))
sns.heatmap(cm,annot = True, fmt='.3f', linewidth=.5,square=True,cmap='Blues_r')
plt.xlabel('Actual label')
plt.ylabel('Predicted label')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy)
plt.title(all_sample_title,size = 15)
plt.show()


#A receiver operating characteristic curve (ROC curve)
#не уверена, наксолько  верно подправила эту ROC кривую.

y_pred_log_tr = y_pred_log.transpose()

fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_log_tr )
auc = metrics.roc_auc_score(y_test,  y_pred_log_tr )
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('A receiver operating characteristic curve')
plt.legend(loc="lower right")


 # the tenth variant:
# w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 0.5
# n_iterations = 10000
# eta = 0.005
#threshold = 0.5

def Sigmoid(x):
    return 1/(1 + np.exp(-x))


#making some data
classes = datasets.make_classification(n_samples=10000, n_features=2, n_informative=2,
                                       n_redundant=0, n_classes=2, random_state=42)


np.random.seed(42)
shuffle_index = np.random.permutation(classes[0].shape[0])
X_shuffled, y_shuffled = classes[0][shuffle_index], classes[1][shuffle_index]
train_proportion = 0.7
train_test_cut = int(len(classes[0]) * train_proportion)

X_train, X_test, y_train, y_test = \
    X_shuffled[:train_test_cut], \
    X_shuffled[train_test_cut:], \
    y_shuffled[:train_test_cut], \
    y_shuffled[train_test_cut:]
X_train_tr = X_train.transpose()
y_train_tr = y_train.reshape(1, y_train.shape[0])
X_test_tr = X_test.transpose()
y_test_tr = y_test.reshape(1, y_test.shape[0])


ss_train = StandardScaler()
X_train = ss_train.fit_transform(X_train)

ss_test = StandardScaler()
X_test = ss_test.fit_transform(X_test)



def log_loss(w, X, y):
    m = X.shape[1]
    A = Sigmoid(np.dot(w.T, X))
    loss = -1.0 / m * np.sum(y * np.log(A) + (1 - y) * np.log(1 - A))
    loss = np.squeeze(loss)
    grad = 1.0 / m * np.dot(X, (A - y).T)
    
    return loss, grad

def optimize(w, X, y, n_iterations, eta):
    losses = []
    X = np.vstack((np.ones((1,X.shape[1])),X))
    for i in range(n_iterations):        
        loss, grad = log_loss(w, X, y)
        w = w - eta * grad
        losses.append(loss)
        
    return w, losses


def predict(w, X):
    
    m = X.shape[1]
    X = np.vstack((np.ones((1,X.shape[1])),X))

    y_predicted = np.zeros((1, m))
    w = w.reshape(X.shape[0], 1)
    A = Sigmoid(np.dot(w.T, X))
    
    for i in range(A.shape[1]):
        if (A[:,i] > 0.5): 
            y_predicted[:, i] = 1
        elif (A[:,i] <= 0.5):
            y_predicted[:, i] = 0
    return y_predicted


w0 = np.zeros((X_train_tr.shape[0] + 1 , 1)) + 0.5

n_iterations = 10000
eta = 0.005

w, losses = optimize(w0, X_train_tr, y_train_tr, n_iterations, eta)

y_predicted_test = predict(w, X_test_tr)
y_predicted_train = predict(w, X_train_tr)

train_accuracy = 100.0 - np.mean(np.abs(y_predicted_train - y_train_tr)*100.0)
test_accuracy = 100.0 - np.mean(np.abs(y_predicted_test-y_test_tr)*100.0)
print(f"Итоговый вектор весов w: {w}")
print(f"Точность на обучающей выборке: {train_accuracy:.3f}")
print(f"Точность на тестовой выборке: {test_accuracy:.3f}")

xl = np.array([[1,1],[-2,2],[-2,2]])*0.9
yt = np.dot(w.T, xl)

colors = ListedColormap(['red', 'blue','green'])
y_x = predict(w,classes[0].T)

plt.title('Log loss')
plt.xlabel('iterations')
plt.ylabel('loss')
plt.plot(range(len(losses)), losses)

plt.figure(figsize=(25, 16))
plt.subplot(1,2,1)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=classes[1], cmap=colors)
plt.grid()
plt.title('True y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.subplot(1,2,2)
plt.scatter([x[0] for x in classes[0]], [x[1] for x in classes[0]], c=y_x.reshape(-1), cmap=colors)
plt.grid()
plt.title('Predict y')
plt.xlabel('x0')
plt.ylabel('x1')
plt.show()

# print(y_test.shape)
# print(y_predicted_test.shape)
# lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)


#ROC-AUC


X_test_tr_sig = np.vstack((np.ones((1, X_test_tr.shape[1])),X_test_tr))
y_pred_log = Sigmoid(np.dot(w.T, X_test_tr_sig))
N = 50
plt.figure(figsize = (16, 5))
plt.subplot(1,2,1)
plt.plot(y_predicted_test[0,:N], 'r' , label = 'true')
plt.plot(y_test_tr[0,:N], '--', label = "class predict")
plt.legend()

plt.subplot(1,2,2)
plt.plot(y_predicted_test[0,:N], "r", label ="true")
plt.plot(y_pred_log[0,:N], "--", label = "log predict")
plt.legend()

plt.show()
y = pd.DataFrame(y_pred_log[0,:])
y[1] = y_test_tr[0,:]

TPR = []
FPR = []

for i in range (len(y.iloc[:,0])):
  tresholds = y.iloc[i,0]- 0.00000000001
  y_p = y.iloc[:,0]>tresholds
  c = [[np.sum((y.iloc[:,1]== 1) & (y_p == y.iloc[:,1])), np.sum((y.iloc[:,1] ==1) &(y_p != y.iloc[:,1]))],
       [np.sum((y.iloc[:,1] == 0) & (y_p != y.iloc[:,1])), np.sum((y.iloc[:,1] == 0)& (y_p == y.iloc[:,1]))]]
  TP = c[0][0]
  TN = c[1][1]
  FP = c[1][0]
  FN = c[0][1]

  TPR.append(TP/(TP+FN))
  FPR.append(FP/(FP+TN))

AUC_ROC = trapz(TPR, x = FPR, dx = 0.1)

plt.title('ROC curve')
plt.ylim(0, 1.05)
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.grid()
plt.legend('', title = f'AUC_ROC = {AUC_ROC:.3f}', loc="lower right")
plt.plot(FPR,TPR)
plt.show()



#импортированные встроенные метрики
# вопрос: насколько им можно верить?

lr_pred = y_predicted_test.transpose()
# print(lr_pred.shape)

#f1_score
from sklearn.metrics import f1_score
f1= f1_score(y_test,  lr_pred ,  average=None, zero_division="warn")
print(f'cреднее гармоническое точности и полноты f1_score:{f1} ')

#доля правильных ответов, точность, полнота алгоритма 
accuracy = accuracy_score(lr_pred, y_test)
precision = precision_score(lr_pred , y_test)
recall = recall_score(lr_pred , y_test)
print(f'доля правильных ответов алгоритма logR: {accuracy}, точность алгоритма logR:  {precision}, полнота алгоритма logR:  {recall} ')

#матрицa ошибок

cm = metrics.confusion_matrix(y_test, lr_pred)
plt.figure(figsize=(9,9))
sns.heatmap(cm,annot = True, fmt='.3f', linewidth=.5,square=True,cmap='Blues_r')
plt.xlabel('Actual label')
plt.ylabel('Predicted label')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy)
plt.title(all_sample_title,size = 15)
plt.show()


#A receiver operating characteristic curve (ROC curve)
#не уверена, наксолько  верно подправила эту ROC кривую.

y_pred_log_tr = y_pred_log.transpose()

fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_log_tr )
auc = metrics.roc_auc_score(y_test,  y_pred_log_tr )
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('A receiver operating characteristic curve')
plt.legend(loc="lower right")
